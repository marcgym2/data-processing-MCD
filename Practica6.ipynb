{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f472544a-ffeb-45f0-a765-747b314de81b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Dataset Management and Labeling and Feature Extraction\n",
    "\n",
    " La base de datos fue organizada en directorios etiquetados para facilitar su manejo y acceso, consolidando los datos con ruido y sin ruido.\n",
    " \n",
    " Posteriormente, se extrajeron las características de cada archivo de audio, calculando el espectrograma de Mel para capturar la esencia frecuencial de las señales. Se estandarizaron las muestras mediante relleno de ceros para unificar las dimensiones, resultando en un conjunto de 18,908 características con sus respectivas etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "daaf51e9-e68b-43a9-ad8f-b041da572ec8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of features: 18908\n",
      "Total number of labels: 18908\n"
     ]
    }
   ],
   "source": [
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def pad_audio(audio, max_length):\n",
    "    return np.pad(audio, (0, max(0, max_length - len(audio))), mode='constant')\n",
    "\n",
    "def extract_mel_spectrogram(file_path, max_length=16000, n_mels=64, n_fft=2048, hop_length=512):\n",
    "    try:\n",
    "        audio, sr = librosa.load(file_path, sr=None)\n",
    "        audio = pad_audio(audio, max_length)\n",
    "        S = librosa.feature.melspectrogram(y=audio, sr=sr, n_mels=n_mels, n_fft=n_fft, hop_length=hop_length)\n",
    "        S_DB = librosa.power_to_db(S, ref=np.max)\n",
    "        return S_DB.T  \n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "        return None\n",
    "\n",
    "def load_data(directory):\n",
    "    features = []\n",
    "    labels = []\n",
    "\n",
    "    for subdir, dirs, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.wav'):\n",
    "                file_path = os.path.join(subdir, file)\n",
    "                mel_spectrogram = extract_mel_spectrogram(file_path)\n",
    "                if mel_spectrogram is not None:\n",
    "                    features.append(mel_spectrogram)\n",
    "                    labels.append(os.path.basename(subdir))  # The directory name is the label\n",
    "\n",
    "    return np.array(features), np.array(labels)\n",
    "\n",
    "# Paths to the datasets\n",
    "clean_directory = '/Users/marcgrayson/Procesamiento de Datos/direction_commands.extracted.tar'\n",
    "noisy_directory = '/Users/marcgrayson/Procesamiento de Datos/direction_commands_with_noise'\n",
    "\n",
    "# Loading the datasets\n",
    "clean_features, clean_labels = load_data(clean_directory)\n",
    "noisy_features, noisy_labels = load_data(noisy_directory)\n",
    "\n",
    "# Combine features and labels from both datasets\n",
    "combined_features = np.concatenate((clean_features, noisy_features), axis=0)\n",
    "combined_labels = np.concatenate((clean_labels, noisy_labels), axis=0)\n",
    "\n",
    "# Checking the number of features and labels to ensure they match\n",
    "print(f\"Total number of features: {len(combined_features)}\")\n",
    "print(f\"Total number of labels: {len(combined_labels)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e80805c-1d63-40de-bc0e-d718a32b3eb5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Feature Selection  \n",
    "Se planea continuar con la selección de características utilizando SelectKBest y la prueba ANOVA F-value para identificar y retener las 100 características más significativas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1782ecf2-a589-435f-89d1-3ec94cb2ced9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "encoded_labels = label_encoder.fit_transform(combined_labels)\n",
    "\n",
    "# SelectKBest con la prueba ANOVA F-value\n",
    "# Seleccionar mejores caracteristicas k\n",
    "\n",
    "selector = SelectKBest(f_classif, k=100)\n",
    "#X_selected = selector.fit_transform(combined_features, encoded_labels)\n",
    "\n",
    "#print(f\"Total number of features before selection: {combined_features.shape[1]}\")\n",
    "#print(f\"Total number of features after selection: {X_selected.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fd9ee75-9a2e-4d7a-914f-cad61219b9e0",
   "metadata": {},
   "source": [
    "# Train Model\n",
    "\n",
    "Con las características seleccionadas, se procederá al entrenamiento de un modelo de red neuronal convolucional. Este modelo se compone de varias capas convolucionales y de agrupamiento, seguidas de capas densas. \n",
    "\n",
    "La arquitectura del modelo ha sido configurada para la clasificación múltiple, con una capa de salida que utiliza la función de activación 'softmax' para predecir las probabilidades de cada comando de voz.\n",
    "\n",
    "El modelo se compila con una función de pérdida de entropía cruzada categórica y el optimizador Adam, una elección adecuada para tareas de clasificación con múltiples clases. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a98a67-b952-4744-bbb7-6fb8960cf2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el modelo de red convolucional 1D\n",
    "model = Sequential()\n",
    "model.add(Conv1D(16, 3, activation='relu', input_shape=(X_train_selected.shape[1], 1)))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv1D(32, 3, activation='relu'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv1D(32, 3, activation='relu'))\n",
    "model.add(MaxPooling1D(2))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(len(class_labels), activation='softmax'))  # Cambio para clasificación múltiple\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(loss='categorical_crossentropy',  # Cambio para clasificación múltiple\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Entrenar el modelo\n",
    "history = model.fit(X_train_selected, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(X_test_selected, np_utils.to_categorical(y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db6b260-6d21-4f25-ad7c-1775928eb4a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Evaluate Model\n",
    "\n",
    "La evaluación del modelo, prevista como el siguiente paso, implicará el uso de un conjunto de datos de prueba para medir su precisión y capacidad de clasificación. Se utilizarán métricas como precisión, sensibilidad y puntuación F1, y se creará una matriz de confusión para detectar y analizar los errores de clasificación. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcb5801-1fa6-4f21-bf2e-97dbc8cf9adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluación del modelo\n",
    "y_pred = model.predict(X_test_selected)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true = np.argmax(np_utils.to_categorical(y_test), axis=1)\n",
    "\n",
    "print(classification_report(y_true, y_pred_classes, target_names=class_labels))\n",
    "conf_matrix = confusion_matrix(y_true, y_pred_classes)\n",
    "print(conf_matrix)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
